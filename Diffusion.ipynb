{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1izo_qnM3SUD",
        "outputId": "a73d5c6c-4590-4679-d6f3-6c11ee3ca536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ===== 1) Imports & device ====================================================\n",
        "import math, os, time, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2) Hyperparameters =====================================================\n",
        "IMG_SIZE   = 28\n",
        "CHANNELS   = 1\n",
        "BATCH_SIZE = 128\n",
        "LR         = 2e-4\n",
        "EPOCHS     = 3          # for demo; increase to ~20-40 for nicer samples\n",
        "T          = 300        # diffusion steps (200-400 is fine for MNIST)\n",
        "\n",
        "beta_start, beta_end = 1e-4, 2e-2   # linear beta schedule"
      ],
      "metadata": {
        "id": "Rv-QyXBJ4Gij"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                   # [0,1]\n",
        "    transforms.Lambda(lambda x: x * 2 - 1),  # -> [-1,1]\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST(root=\"./data\", train=True,  download=True, transform=transform)\n",
        "test_set  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "def plot_tensor_grid(x, nrow=8, title=None):\n",
        "    \"\"\"\n",
        "    x: [B, C, H, W] in [-1,1]; display first nrow*nrow images\n",
        "    \"\"\"\n",
        "    x = (x[: nrow*nrow].detach().cpu() + 1) / 2  # -> [0,1]\n",
        "    grid = utils.make_grid(x, nrow=nrow, padding=2)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(grid.permute(1,2,0).squeeze(), interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "    if title: plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A0AukVU4Yp_",
        "outputId": "24a38239-642c-4447-ace1-580f07523afe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 62.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.75MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.34MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "betas  = torch.linspace(beta_start, beta_end, T, device=DEVICE)\n",
        "alphas = 1.0 - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=DEVICE), alphas_cumprod[:-1]])\n",
        "\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "# DDPM posterior variance (Eq. 7)\n",
        "posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "# ===== 5) q_sample: forward/noising ==========================================\n",
        "def q_sample(x0, t, noise=None):\n",
        "    \"\"\"\n",
        "    Sample x_t ~ q(x_t | x_0) in closed form:\n",
        "        x_t = sqrt(alpha_bar_t) * x0 + sqrt(1 - alpha_bar_t) * eps\n",
        "    x0   : [B, C, H, W] in [-1,1]\n",
        "    t    : [B] int64 timesteps\n",
        "    noise: [B, C, H, W], standard normal; if None, sampled here\n",
        "    \"\"\"\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x0)\n",
        "    s1 = sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)  # underroot alpha\n",
        "    s2 = sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1) # 1- underroot alpha\n",
        "    return s1 * x0 + s2 * noise\n",
        "\n",
        "# ===== 6) Sinusoidal timestep embedding ======================================\n",
        "def timestep_embedding(timesteps, dim=64):\n",
        "    \"\"\"\n",
        "    Create sinusoidal embeddings for integer timesteps.\n",
        "    timesteps: [B] int64\n",
        "    returns  : [B, dim]\n",
        "    \"\"\"\n",
        "    device = timesteps.device\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(-math.log(10000) * torch.arange(0, half, device=device).float() / half)  # [half]\n",
        "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)                                  # [B, half]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=1)                                  # [B, 2*half]\n",
        "    if dim % 2 == 1:\n",
        "        emb = F.pad(emb, (0,1))\n",
        "    return emb"
      ],
      "metadata": {
        "id": "zGTK7Mcz519Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, c_in, c_out, t_emb_dim=64):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(8, c_in)\n",
        "        self.conv1 = nn.Conv2d(c_in, c_out, 3, padding=1)\n",
        "        self.norm2 = nn.GroupNorm(8, c_out)\n",
        "        self.conv2 = nn.Conv2d(c_out, c_out, 3, padding=1)\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(t_emb_dim, c_out * 2)  # scale & shift\n",
        "        )\n",
        "        self.skip = nn.Conv2d(c_in, c_out, 1) if c_in != c_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        # t_emb -> (gamma, beta) for FiLM conditioning\n",
        "        temb = self.time_mlp(t_emb)[:, :, None, None]\n",
        "        gamma, beta = temb.chunk(2, dim=1)\n",
        "\n",
        "        h = self.conv1(F.silu(self.norm1(x)))\n",
        "        h = h * (1 + gamma) + beta\n",
        "        h = self.conv2(F.silu(self.norm2(h)))\n",
        "        return h + self.skip(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, c_in, c_out, t_emb_dim=64):\n",
        "        super().__init__()\n",
        "        self.b1 = ResBlock(c_in, c_out, t_emb_dim)\n",
        "        self.b2 = ResBlock(c_out, c_out, t_emb_dim)\n",
        "        self.down = nn.Conv2d(c_out, c_out, 4, stride=2, padding=1)  # 2x downsample\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        x = self.b1(x, t_emb)\n",
        "        x = self.b2(x, t_emb)\n",
        "        skip = x\n",
        "        x = self.down(x)\n",
        "        return x, skip\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, c_in, c_skip, c_out, t_emb_dim=64):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(c_in, c_out, 4, stride=2, padding=1)  # 2x upsample: c_in -> c_out\n",
        "        self.b1 = ResBlock(c_out + c_skip, c_out, t_emb_dim)               # after concat\n",
        "        self.b2 = ResBlock(c_out, c_out, t_emb_dim)\n",
        "\n",
        "    def forward(self, x, skip, t_emb):\n",
        "        x = self.up(x)                       # spatial: 7->14 or 14->28, channels: c_in->c_out\n",
        "        x = torch.cat([x, skip], dim=1)      # concat with skip (same H,W now)\n",
        "        x = self.b1(x, t_emb)\n",
        "        x = self.b2(x, t_emb)\n",
        "        return x\n",
        "\n",
        "class UNetMNIST(nn.Module):\n",
        "    def __init__(self, c=CHANNELS, base=64, t_emb_dim=64):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(t_emb_dim, t_emb_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(t_emb_dim * 4, t_emb_dim),\n",
        "        )\n",
        "\n",
        "        self.in_conv = nn.Conv2d(c, base, 3, padding=1)\n",
        "\n",
        "        self.down1 = Down(base, base, t_emb_dim)         # out: base,     skip s1 @ 28x28\n",
        "        self.down2 = Down(base, base * 2, t_emb_dim)     # out: base*2,   skip s2 @ 14x14\n",
        "\n",
        "        self.mid1 = ResBlock(base * 2, base * 2, t_emb_dim)\n",
        "        self.mid2 = ResBlock(base * 2, base * 2, t_emb_dim)\n",
        "\n",
        "        # Up: (c_in_from_prev, c_skip, c_out_after_up)\n",
        "        self.up1 = Up(base * 2, base * 2, base, t_emb_dim)  # 7->14, concat with s2 (base*2), out base\n",
        "        self.up2 = Up(base,     base,     base, t_emb_dim)  # 14->28, concat with s1 (base),   out base\n",
        "\n",
        "        self.out_norm = nn.GroupNorm(8, base)\n",
        "        self.out_conv = nn.Conv2d(base, c, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t_emb = timestep_embedding(t, dim=64)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "\n",
        "        x = self.in_conv(x)\n",
        "        x, s1 = self.down1(x, t_emb)   # s1: [B, base,     28, 28]\n",
        "        x, s2 = self.down2(x, t_emb)   # s2: [B, base*2,   14, 14]\n",
        "\n",
        "        x = self.mid1(x, t_emb)        # x:  [B, base*2,    7,  7]\n",
        "        x = self.mid2(x, t_emb)\n",
        "\n",
        "        x = self.up1(x, s2, t_emb)     # -> [B, base,      14, 14]\n",
        "        x = self.up2(x, s1, t_emb)     # -> [B, base,      28, 28]\n",
        "\n",
        "        x = F.silu(self.out_norm(x))\n",
        "        x = self.out_conv(x)           # [B, 1, 28, 28]\n",
        "        return x\n",
        "\n",
        "model = UNetMNIST().to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.0)"
      ],
      "metadata": {
        "id": "BRdxedGw9gI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(ep):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for i, (x0, _) in enumerate(train_loader):\n",
        "        x0 = x0.to(DEVICE)                                  # [B,1,28,28] in [-1,1]\n",
        "        t  = torch.randint(0, T, (x0.size(0),), device=DEVICE).long()\n",
        "        eps = torch.randn_like(x0)                          # true noise\n",
        "        x_t = q_sample(x0, t, eps)                          # forward/noised sample\n",
        "\n",
        "        eps_pred = model(x_t, t)                            # predict noise\n",
        "        loss = F.mse_loss(eps_pred, eps)                    # ε-pred loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running += loss.item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch {ep}  |  Step {i+1:4d}/{len(train_loader)}  |  loss={running/100:.4f}\")\n",
        "            running = 0.0"
      ],
      "metadata": {
        "id": "p7glOSWZ-IBo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reverse"
      ],
      "metadata": {
        "id": "9_LRa-f0DTQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def p_sample(x_t, t):\n",
        "    \"\"\"\n",
        "    One reverse step: x_t -> x_{t-1}\n",
        "    Uses Eq.(11) mean and posterior variance from DDPM.\n",
        "    \"\"\"\n",
        "    eps_theta = model(x_t, t)\n",
        "    alpha_t   = alphas[t].view(-1,1,1,1)\n",
        "    beta_t    = betas[t].view(-1,1,1,1)\n",
        "    sqrt_one_minus_ac = sqrt_one_minus_alphas_cumprod[t].view(-1,1,1,1)\n",
        "    sqrt_recip_alpha  = sqrt_recip_alphas[t].view(-1,1,1,1)\n",
        "\n",
        "    # Model mean (Eq. 11)\n",
        "    model_mean = sqrt_recip_alpha * (x_t - (beta_t / sqrt_one_minus_ac) * eps_theta)\n",
        "\n",
        "    # At t=0, no further noise\n",
        "    if (t == 0).all():\n",
        "        return model_mean\n",
        "\n",
        "    var = posterior_variance[t].view(-1,1,1,1)\n",
        "    noise = torch.randn_like(x_t)\n",
        "    return model_mean + torch.sqrt(var) * noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(n=64):\n",
        "    \"\"\"\n",
        "    Draw n samples by ancestral sampling from x_T ~ N(0,I).\n",
        "    Returns: [n,1,28,28] in [-1,1]\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x_t = torch.randn(n, CHANNELS, IMG_SIZE, IMG_SIZE, device=DEVICE)\n",
        "    for step in reversed(range(T)):\n",
        "        t = torch.full((n,), step, device=DEVICE, dtype=torch.long)\n",
        "        x_t = p_sample(x_t, t)\n",
        "    return x_t.clamp(-1, 1)"
      ],
      "metadata": {
        "id": "JZy-1MV1CNbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(1, EPOCHS + 1):\n",
        "    train_epoch(ep)\n",
        "    # quick qualitative check each epoch\n",
        "    with torch.no_grad():\n",
        "        imgs = sample(36)  # 6x6 grid for speed\n",
        "    plot_tensor_grid(imgs, nrow=6, title=f\"Epoch {ep} samples\")\n"
      ],
      "metadata": {
        "id": "PeL-RhXCCRLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFX68ldOCT6e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}